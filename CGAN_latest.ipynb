{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B920G1upl-sH",
        "outputId": "a02ef83b-c15e-469e-f542-bcbd891fe12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/examples.git\n",
            "  Cloning https://github.com/tensorflow/examples.git to /tmp/pip-req-build-ja5i1ye3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/examples.git /tmp/pip-req-build-ja5i1ye3\n",
            "  Resolved https://github.com/tensorflow/examples.git to commit fff4bcda7201645a1efaea4534403daf5fc03d42\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-examples==0.1703207612.1461250479831370929614362828255168868146460245314) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow-examples==0.1703207612.1461250479831370929614362828255168868146460245314) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "9UmpmzKxmI6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# special need for Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/DocDenoise\")\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUP5ysM6my8s",
        "outputId": "f941986e-1ee2-43fa-96b9-3579a4ba806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "adaptive_threshold.m  denoising_cg.ipynb  README.md\t\t   training_ae.ipynb\n",
            "checkpoints\t      easy_ocr.ipynb\t  skew_correction.ipynb    training_cg.ipynb\n",
            "data\t\t      images\t\t  table_recognition.ipynb  zip\n",
            "denoising_ae.ipynb    paddle_ocr.ipynb\t  tesseract_ocr.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojf9zjLmm2tk",
        "outputId": "2f66aac3-f69f-4eae-be21-8526371195b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_zip = 'zip/'\n",
        "path = 'data/'"
      ],
      "metadata": {
        "id": "4R-TLSF9oY3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n"
      ],
      "metadata": {
        "id": "xvQE_z8yqImE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip files first to working directory\n",
        "with zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "with zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)\n",
        "\n",
        "with zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "Cxt-YeqQo28Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img = sorted(os.listdir(path + 'train/'))\n",
        "train_cleaned_img = sorted(os.listdir(path + 'train_cleaned/'))\n",
        "test_img = sorted(os.listdir(path + 'test/'))\n",
        "#test_invoice_img = sorted(os.listdir(path + 'test_invoice/'))"
      ],
      "metadata": {
        "id": "By8i9bsRpfHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512\n",
        "\n",
        "# prepare function\n",
        "def process_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = np.asarray(img, dtype=\"float32\")\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    img = img/255.0\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "xran3oFsqPc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = []\n",
        "train_cleaned = []\n",
        "test = []\n",
        "test_invoice = []\n",
        "\n",
        "for f in train_img:\n",
        "    train.append(process_image(path + 'train/' + f))\n",
        "\n",
        "for f in train_cleaned_img:\n",
        "    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n",
        "\n",
        "for f in test_img:\n",
        "    test.append(process_image(path + 'test/' + f))\n",
        "\n",
        "#for f in test_invoice_img:\n",
        " #   test_invoice.append(process_image(path + 'test_invoice/' + f))"
      ],
      "metadata": {
        "id": "K6UMxw4Bq6II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert list to numpy array\n",
        "X_train = np.asarray(train)\n",
        "Y_train = np.asarray(train_cleaned)\n",
        "X_test = np.asarray(test)\n",
        "X_test_invoice = np.asarray(test_invoice)"
      ],
      "metadata": {
        "id": "PWo7UM2Eq9fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "\n",
        "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "\n",
        "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
        "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
      ],
      "metadata": {
        "id": "EPNb5RjhrE7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LAMBDA = 10\n"
      ],
      "metadata": {
        "id": "Rx9EV0PnrIOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "piEqHQ18rLbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real, generated):\n",
        "  real_loss = loss_obj(tf.ones_like(real), real)\n",
        "\n",
        "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss * 0.5"
      ],
      "metadata": {
        "id": "-3poqimerTLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(generated):\n",
        "  return loss_obj(tf.ones_like(generated), generated)"
      ],
      "metadata": {
        "id": "B-t6lpdtrUBB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_cycle_loss(real_image, cycled_image):\n",
        "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "  return LAMBDA * loss1"
      ],
      "metadata": {
        "id": "5RgcXs7YrWsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_loss(real_image, same_image):\n",
        "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "  return LAMBDA * 0.5 * loss\n"
      ],
      "metadata": {
        "id": "T3yK62z2rcnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n"
      ],
      "metadata": {
        "id": "wGJd00d9rff7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/cycleGAN\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           generator_f=generator_f,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           discriminator_y=discriminator_y,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           generator_f_optimizer=generator_f_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
        "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')\n",
        "else:\n",
        "  print('no')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tg7JrDrrjqM",
        "outputId": "07b99c29-2275-426a-f160-bd9a3c657b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model, test_input, epoch):\n",
        "  prediction = model(test_input)\n",
        "\n",
        "  plt.figure(figsize=(12, 12))\n",
        "\n",
        "  display_list = [test_input[0], prediction[0]]\n",
        "  title = ['Input Image', 'Predicted Image']\n",
        "\n",
        "  for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(display_list[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig('images/'+str(epoch)+'.png')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Bz6eQKucrnP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "  # persistent is set to True because the tape is used more than\n",
        "  # once to calculate the gradients.\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Generator G translates X -> Y\n",
        "    # Generator F translates Y -> X.\n",
        "\n",
        "    fake_y = generator_g(real_x, training=True)\n",
        "    cycled_x = generator_f(fake_y, training=True)\n",
        "\n",
        "    fake_x = generator_f(real_y, training=True)\n",
        "    cycled_y = generator_g(fake_x, training=True)\n",
        "\n",
        "    # same_x and same_y are used for identity loss.\n",
        "    same_x = generator_f(real_x, training=True)\n",
        "    same_y = generator_g(real_y, training=True)\n",
        "\n",
        "    disc_real_x = discriminator_x(real_x, training=True)\n",
        "    disc_real_y = discriminator_y(real_y, training=True)\n",
        "\n",
        "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
        "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
        "\n",
        "    # calculate the loss\n",
        "    gen_g_loss = generator_loss(disc_fake_y)\n",
        "    gen_f_loss = generator_loss(disc_fake_x)\n",
        "\n",
        "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        "\n",
        "    # Total generator loss = adversarial loss + cycle loss\n",
        "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
        "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "\n",
        "  # Calculate the gradients for generator and discriminator\n",
        "  generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
        "  generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
        "\n",
        "  discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
        "  discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
        "\n",
        "  # Apply the gradients to the optimizer\n",
        "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
        "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
        "\n",
        "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))"
      ],
      "metadata": {
        "id": "xboIb9rMr33p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "-x6SN2nAsJ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "batch_size = 6\n",
        "\n",
        "def batch_generator(X_train, Y_train, batch_size):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        yield X_train[i:i+batch_size], Y_train[i:i+batch_size]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_x, image_y in batch_generator(X_train, Y_train, batch_size):\n",
        "        train_step(image_x, image_y)\n",
        "        print('.', end='')\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Using a consistent image (sample_horse) so that the progress of the model\n",
        "    # is clearly visible.\n",
        "    generate_images(generator_g, X_test[0].reshape(1, 512, 512, 3), epoch + 1)\n",
        "    generate_images(generator_f, Y_train[0].reshape(1, 512, 512, 3), -epoch - 1)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print('Time taken for epoch {} is {} sec\\n'.format(epoch+1, time.time()-start))\n"
      ],
      "metadata": {
        "id": "4mR0N5eYr9xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc  # Import the garbage collector module\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 6\n",
        "\n",
        "def batch_generator(X_train, Y_train, batch_size):\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        yield X_train[i:i+batch_size], Y_train[i:i+batch_size]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_x, image_y in batch_generator(X_train, Y_train, batch_size):\n",
        "        train_step(image_x, image_y)\n",
        "        print('.', end='')\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # Using a consistent image (sample_horse) so that the progress of the model\n",
        "    # is clearly visible.\n",
        "    generate_images(generator_g, X_test[0].reshape(1, 512, 512, 3), epoch + 1)\n",
        "    generate_images(generator_f, Y_train[0].reshape(1, 512, 512, 3), -epoch - 1)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print('Time taken for epoch {} is {} sec\\n'.format(epoch+1, time.time()-start))\n",
        "\n",
        "    # Explicitly release memory using garbage collector\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "JIUdI3CCyJhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inp in X_test[:4]:\n",
        "  generate_images(generator_g, inp.reshape(1,512,512,3), 0)\n"
      ],
      "metadata": {
        "id": "jsnF6mVksAeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}